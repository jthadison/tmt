# Story 7.2: Learning Circuit Breaker Implementation

## Status
Ready

## Story
**As a** safety system,  
**I want** to prevent learning during suspicious conditions,  
**so that** the system doesn't learn from poisoned data.

## Acceptance Criteria
1. Learning disabled during unusual market conditions (flash crashes, gaps)
2. Anomaly detection on win rates (sudden improvements = suspicious)
3. Data quarantine for suspicious periods pending manual review
4. Learning rollback capability to previous stable state
5. A/B testing framework for gradual change validation
6. Manual override to force or prevent learning periods

## Tasks / Subtasks

- [ ] Task 1: Build market condition anomaly detection (AC: 1)
  - [ ] Create flash crash detection algorithms
  - [ ] Implement gap detection and classification
  - [ ] Build volatility spike detection
  - [ ] Add news event impact assessment
  - [ ] Create market condition learning triggers
  
- [ ] Task 2: Implement performance anomaly detection (AC: 2)
  - [ ] Create win rate anomaly detection
  - [ ] Build sudden improvement detection algorithms
  - [ ] Implement performance consistency monitoring
  - [ ] Add statistical significance testing
  - [ ] Create performance anomaly alerting
  
- [ ] Task 3: Build data quarantine system (AC: 3)
  - [ ] Create quarantine data storage
  - [ ] Implement quarantine decision engine
  - [ ] Build manual review workflow
  - [ ] Add quarantine release mechanisms
  - [ ] Create quarantine analytics and reporting
  
- [ ] Task 4: Implement learning rollback system (AC: 4)
  - [ ] Create model versioning and snapshotting
  - [ ] Build rollback detection triggers
  - [ ] Implement automated rollback mechanisms
  - [ ] Add rollback validation testing
  - [ ] Create rollback audit trail
  
- [ ] Task 5: Develop A/B testing framework (AC: 5)
  - [ ] Create test group assignment system
  - [ ] Build performance comparison analytics
  - [ ] Implement statistical significance testing
  - [ ] Add automated promotion/rollback decisions
  - [ ] Create A/B test reporting dashboard
  
- [ ] Task 6: Build manual override controls (AC: 6)
  - [ ] Create manual learning control interface
  - [ ] Implement override authorization system
  - [ ] Build override impact assessment
  - [ ] Add override audit logging
  - [ ] Create override dashboard and monitoring

## Dev Notes

### Architecture Context
This story implements critical safety mechanisms that prevent the learning system from being corrupted by abnormal market conditions, manipulation attempts, or other data poisoning scenarios. This is essential for maintaining system integrity and preventing the AI from learning harmful behaviors.

### Circuit Breaker Philosophy
[Source: docs/architecture/learning-safety.md]
The learning circuit breaker follows the principle of "fail-safe" operation:
- **Conservative by Default**: When in doubt, don't learn
- **Multiple Validation Layers**: Multiple independent checks before learning
- **Graceful Degradation**: System continues trading but stops adapting
- **Quick Recovery**: Rapid return to learning when conditions normalize
- **Human Oversight**: Manual controls for complex scenarios

### Safety Mechanisms
[Source: docs/architecture/safety-mechanisms.md]
```
Learning Pipeline: Data → Validation → Circuit Breaker → Learning Engine
                                      ↓
                               Quarantine System ← Manual Review
```

### Data Models
[Source: docs/architecture/data-models.md]
```typescript
interface LearningCircuitBreaker {
  id: string;
  status: 'closed' | 'open' | 'half_open' | 'forced_open' | 'forced_closed';
  
  // Configuration
  config: {
    marketConditionThresholds: MarketConditionThresholds;
    performanceThresholds: PerformanceThresholds;
    dataQualityThresholds: DataQualityThresholds;
    timeBasedRules: TimeBasedRule[];
  };
  
  // Current State
  currentState: {
    learningEnabled: boolean;
    lastStateChange: Date;
    stateChangeReason: string;
    consecutiveAnomalies: number;
    recoveryProgress: number; // 0-1
    manualOverride: boolean;
    overrideReason?: string;
    overrideBy?: string;
  };
  
  // Monitoring
  monitoring: {
    marketConditions: MarketConditionStatus;
    performanceMetrics: PerformanceStatus;
    dataQuality: DataQualityStatus;
    systemHealth: SystemHealthStatus;
  };
  
  // History
  stateHistory: CircuitBreakerEvent[];
  quarantinedPeriods: QuarantinePeriod[];
  rollbackEvents: RollbackEvent[];
}

interface MarketConditionThresholds {
  // Volatility thresholds
  maxVolatilitySpike: number;        // 3x normal volatility
  maxGapSize: number;                // 100+ pips
  maxPriceMovement: number;          // 5% in 5 minutes
  
  // Volume thresholds
  minVolumeForLearning: number;      // Minimum volume required
  maxVolumeSpike: number;            // 10x normal volume
  
  // Spread thresholds
  maxSpreadWidening: number;         // 5x normal spread
  
  // News event impact
  newsEventLockoutMinutes: number;   // 60 minutes after high-impact news
  
  // Market hours
  excludeMarketOpen: boolean;        // First 30 minutes
  excludeMarketClose: boolean;       // Last 30 minutes
  excludeWeekendGaps: boolean;       // Sunday evening gaps
}

interface PerformanceThresholds {
  // Win rate anomaly detection
  maxWinRateIncrease: number;        // 15% increase over 100 trades
  minSampleSizeForAnomalyCheck: number; // 50 trades minimum
  
  // Performance consistency
  maxSharpeImprovement: number;      // 50% Sharpe ratio increase
  maxProfitFactorIncrease: number;   // 30% profit factor increase
  
  // Statistical significance
  minPValueForSuspicion: number;     // p < 0.01 is suspicious
  confidenceIntervalThreshold: number; // 95% confidence required
  
  // Performance degradation
  maxDrawdownIncrease: number;       // 20% drawdown increase
  maxConsecutiveLosses: number;      // 10 consecutive losses
}

interface DataQualityThresholds {
  minDataCompleteness: number;       // 95% feature completeness
  maxAnomalyScore: number;           // 0.9 max anomaly score
  maxValidationErrors: number;       // 5% max validation error rate
  minDataFreshness: number;          // Data must be < 5 minutes old
}

interface CircuitBreakerEvent {
  timestamp: Date;
  eventType: 'opened' | 'closed' | 'half_opened' | 'forced_override';
  reason: string;
  trigger: AnomalyDetection;
  impact: {
    affectedModels: string[];
    quarantinedDataCount: number;
    learningPaused: boolean;
  };
  resolution: {
    resolvedAt?: Date;
    resolutionMethod: string;
    manualIntervention: boolean;
  };
}

interface AnomalyDetection {
  detectionId: string;
  timestamp: Date;
  category: 'market_condition' | 'performance' | 'data_quality' | 'systematic';
  
  // Detection details
  anomalyType: string;
  severity: 'low' | 'medium' | 'high' | 'critical';
  confidence: number; // 0-1
  
  // Metrics
  observedValue: number;
  expectedValue: number;
  threshold: number;
  deviationMagnitude: number;
  
  // Context
  marketContext: MarketContext;
  affectedAccounts: string[];
  potentialCauses: string[];
  
  // Action taken
  actionTaken: 'none' | 'quarantine' | 'circuit_breaker_open' | 'manual_review';
  recommendation: string;
}

interface QuarantinePeriod {
  id: string;
  startTime: Date;
  endTime?: Date;
  
  // Quarantine reason
  trigger: AnomalyDetection;
  quarantineReason: string;
  severity: 'low' | 'medium' | 'high' | 'critical';
  
  // Quarantined data
  quarantinedRecords: number;
  quarantinedAccounts: string[];
  dataTypes: string[]; // trades, signals, market_data
  
  // Review status
  reviewStatus: 'pending' | 'in_review' | 'approved' | 'rejected' | 'partial_approval';
  reviewer?: string;
  reviewNotes?: string;
  reviewedAt?: Date;
  
  // Release decision
  releaseDecision: {
    released: boolean;
    releaseReason: string;
    releasedAt?: Date;
    dataUsageDecision: 'use_all' | 'use_partial' | 'discard_all';
  };
}

interface ABTest {
  testId: string;
  testName: string;
  
  // Test configuration
  testConfig: {
    startDate: Date;
    endDate: Date;
    rolloutPercentage: number; // 10%, 25%, 50%, 100%
    controlGroupSize: number;
    testGroupSize: number;
  };
  
  // Test groups
  controlGroup: {
    accountIds: string[];
    baselineMetrics: PerformanceMetrics;
    currentMetrics: PerformanceMetrics;
  };
  
  testGroup: {
    accountIds: string[];
    baselineMetrics: PerformanceMetrics;
    currentMetrics: PerformanceMetrics;
    changesApplied: ModelChange[];
  };
  
  // Statistical analysis
  statisticalAnalysis: {
    sampleSize: number;
    powerAnalysis: number;
    pValue: number;
    confidenceInterval: number;
    effectSize: number;
    statisticallySignificant: boolean;
  };
  
  // Test results
  results: {
    performanceDifference: number; // Percentage difference
    winnerGroup: 'control' | 'test' | 'inconclusive';
    recommendation: 'rollout' | 'rollback' | 'extend_test' | 'manual_review';
    automaticAction: boolean;
  };
  
  // Status tracking
  status: 'planned' | 'running' | 'completed' | 'aborted' | 'rolled_back';
  statusHistory: ABTestEvent[];
}

interface ModelChange {
  changeId: string;
  changeType: 'parameter_adjustment' | 'algorithm_update' | 'feature_addition' | 'threshold_change';
  description: string;
  implementedAt: Date;
  version: string;
  
  // Change details
  parameters: Record<string, any>;
  affectedComponents: string[];
  expectedImpact: string;
  
  // Rollback information
  rollbackData: any;
  canRollback: boolean;
}

interface LearningSnapshot {
  snapshotId: string;
  timestamp: Date;
  version: string;
  
  // Model state
  modelStates: Record<string, any>;
  parameters: Record<string, any>;
  performanceMetrics: PerformanceMetrics;
  
  // Metadata
  description: string;
  trigger: 'scheduled' | 'before_learning' | 'manual' | 'circuit_breaker';
  dataHash: string; // For integrity checking
  
  // Recovery information
  isStable: boolean;
  stabilityScore: number;
  rollbackTarget: boolean;
}
```

### Circuit Breaker Algorithms
[Source: docs/architecture/circuit-breaker-algorithms.md]
```python
class LearningCircuitBreaker:
    def __init__(self):
        self.state = 'closed'  # closed = learning enabled
        self.anomaly_detectors = [
            MarketConditionDetector(),
            PerformanceAnomalyDetector(),
            DataQualityDetector(),
            SystematicPatternDetector()
        ]
        
    def check_learning_safety(self, new_data: TradeData) -> LearningDecision:
        # Run all anomaly detectors
        anomalies = []
        for detector in self.anomaly_detectors:
            anomaly = detector.detect(new_data)
            if anomaly:
                anomalies.append(anomaly)
        
        # Evaluate circuit breaker state
        if anomalies:
            decision = self.evaluate_anomalies(anomalies)
        else:
            decision = LearningDecision(allow_learning=True, reason="No anomalies detected")
        
        # Update circuit breaker state
        self.update_state(decision, anomalies)
        
        return decision
    
    def evaluate_anomalies(self, anomalies: List[AnomalyDetection]) -> LearningDecision:
        # Calculate cumulative risk score
        risk_score = sum(anomaly.confidence * anomaly.severity_weight for anomaly in anomalies)
        
        # Decision matrix based on risk score and anomaly types
        if risk_score > 0.8:
            return LearningDecision(
                allow_learning=False,
                quarantine_data=True,
                reason="High risk score - multiple severe anomalies",
                action_required='immediate_review'
            )
        elif any(anomaly.category == 'market_condition' and anomaly.severity == 'critical' 
                for anomaly in anomalies):
            return LearningDecision(
                allow_learning=False,
                quarantine_data=True,
                reason="Critical market condition anomaly detected",
                action_required='wait_for_stability'
            )
        elif any(anomaly.category == 'performance' and anomaly.confidence > 0.9 
                for anomaly in anomalies):
            return LearningDecision(
                allow_learning=False,
                quarantine_data=True,
                reason="Suspicious performance improvement detected",
                action_required='manual_review'
            )
        else:
            return LearningDecision(
                allow_learning=True,
                monitoring_required=True,
                reason="Low-level anomalies detected - proceed with caution"
            )

class PerformanceAnomalyDetector:
    def detect(self, recent_data: TradeData) -> Optional[AnomalyDetection]:
        # Calculate recent performance metrics
        recent_win_rate = self.calculate_win_rate(recent_data, window=100)
        baseline_win_rate = self.get_baseline_win_rate()
        
        # Detect sudden improvements (suspicious)
        improvement = recent_win_rate - baseline_win_rate
        
        if improvement > 0.15:  # 15% improvement threshold
            # Check if statistically significant
            p_value = self.statistical_test(recent_data, baseline_data)
            
            if p_value < 0.01:  # Highly significant = suspicious
                return AnomalyDetection(
                    category='performance',
                    anomaly_type='suspicious_improvement',
                    severity='high',
                    confidence=1 - p_value,
                    observed_value=recent_win_rate,
                    expected_value=baseline_win_rate,
                    threshold=baseline_win_rate + 0.15
                )
        
        return None

class ABTestFramework:
    def create_test(self, test_config: ABTestConfig, model_changes: List[ModelChange]) -> ABTest:
        # Assign accounts to control and test groups
        control_accounts, test_accounts = self.assign_test_groups(
            test_config.total_accounts, 
            test_config.test_percentage
        )
        
        # Capture baseline metrics
        baseline_metrics = self.capture_baseline_metrics(control_accounts + test_accounts)
        
        # Apply changes to test group
        for change in model_changes:
            self.apply_change_to_accounts(change, test_accounts)
        
        # Create test tracking
        test = ABTest(
            test_config=test_config,
            control_group={'account_ids': control_accounts, 'baseline_metrics': baseline_metrics},
            test_group={'account_ids': test_accounts, 'baseline_metrics': baseline_metrics},
            status='running'
        )
        
        return test
    
    def evaluate_test_results(self, test: ABTest) -> ABTestResult:
        # Gather performance data
        control_performance = self.get_group_performance(test.control_group.account_ids)
        test_performance = self.get_group_performance(test.test_group.account_ids)
        
        # Statistical analysis
        statistical_analysis = self.perform_statistical_analysis(
            control_performance, test_performance
        )
        
        # Make recommendation
        if statistical_analysis.statistically_significant:
            if test_performance.sharpe_ratio > control_performance.sharpe_ratio * 1.05:
                recommendation = 'rollout'
            elif test_performance.sharpe_ratio < control_performance.sharpe_ratio * 0.9:
                recommendation = 'rollback'
            else:
                recommendation = 'inconclusive'
        else:
            recommendation = 'extend_test'
        
        return ABTestResult(
            statistical_analysis=statistical_analysis,
            recommendation=recommendation,
            performance_difference=(test_performance.sharpe_ratio - control_performance.sharpe_ratio) / control_performance.sharpe_ratio
        )
```

### Component Architecture
[Source: docs/architecture/backend-architecture.md]
```
agents/
├── learning-safety/
│   ├── LearningCircuitBreaker.py     # Main circuit breaker logic
│   ├── AnomalyDetectors.py           # Various anomaly detection modules
│   ├── QuarantineManager.py          # Data quarantine system
│   ├── RollbackManager.py            # Model rollback capabilities
│   ├── ABTestFramework.py            # A/B testing system
│   └── ManualOverrideController.py   # Manual control interface
```

### Integration Points
[Source: docs/architecture/system-integration.md]
- **Data Collection Pipeline**: Receives data quality assessments
- **Learning Engine**: Controls when learning is allowed
- **Model Management**: Triggers snapshots and rollbacks
- **Alert System**: Sends notifications for manual review
- **Dashboard**: Provides manual override controls

### Recovery Procedures
[Source: docs/architecture/recovery-procedures.md]
```python
def recovery_procedure(circuit_breaker_event: CircuitBreakerEvent):
    if circuit_breaker_event.category == 'market_condition':
        # Wait for market conditions to normalize
        return WaitForMarketNormalization()
    
    elif circuit_breaker_event.category == 'performance':
        # Requires manual review and potential rollback
        return RequireManualReview()
    
    elif circuit_breaker_event.category == 'data_quality':
        # Fix data pipeline issues
        return DataPipelineRecovery()
    
    else:
        # Conservative approach - manual intervention
        return RequireManualIntervention()
```

### Testing Standards
- Test anomaly detection with known market events
- Verify quarantine system with corrupted data
- Test rollback functionality with model snapshots
- Validate A/B testing statistical accuracy
- Test manual override controls and authorization

## Testing

### Test Requirements
[Source: docs/architecture/testing-strategy.md]
- **Unit Tests**: Anomaly detectors, decision logic, statistical calculations
- **Integration Tests**: End-to-end circuit breaker operation, rollback procedures
- **Scenario Tests**: Market crash simulations, performance anomaly injection
- **Statistical Tests**: A/B test accuracy, significance testing validation
- **Security Tests**: Manual override authorization, audit trail integrity
- **Location**: `agents/learning-safety/__tests__/`

### Specific Testing Focus
- Anomaly detection accuracy and false positive rates
- Circuit breaker response time and decision accuracy
- Quarantine system data integrity and review workflow
- Rollback functionality and model restoration
- A/B testing statistical validity and automation
- Manual override security and audit logging

### Simulation Testing
- **Flash Crash Simulation**: Test circuit breaker response to sudden price movements
- **Performance Manipulation**: Inject artificial performance improvements
- **Data Corruption**: Test with intentionally corrupted data streams
- **System Overload**: Test behavior under high data volume
- **Network Partitions**: Test resilience to connectivity issues

### Mock Data Requirements
- Historical market crash data for anomaly testing
- Artificially improved performance data for suspicious pattern detection
- Corrupted data samples for quarantine testing
- A/B test scenarios with known statistical outcomes
- Model snapshot data for rollback testing

### Performance Benchmarks
- Anomaly detection: < 50ms per data point
- Circuit breaker decision: < 100ms
- Quarantine operation: < 500ms per record
- Rollback execution: < 30 seconds
- A/B test evaluation: < 10 seconds for statistical analysis

## Change Log
| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 2025-01-12 | 1.0 | Initial story creation | Bob (Scrum Master) |

## Dev Agent Record
*This section will be populated by the development agent during implementation.*

### Agent Model Used
*To be filled by dev agent*

### Debug Log References  
*To be filled by dev agent*

### Completion Notes List
*To be filled by dev agent*

### File List
*To be filled by dev agent*

## QA Results
*Results from QA Agent review will be populated here after implementation.*